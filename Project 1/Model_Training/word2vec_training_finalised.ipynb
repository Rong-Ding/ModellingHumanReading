{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train_en.txt\")\n",
    "lines_mod = []\n",
    "pattern = re.compile('[a-zA-Z]+\\'?[a-zA-Z]+') \n",
    "# find strings that begin and end with letters, no matter if there is and only is ONE symble inside\n",
    "# this allows units like \"I'm\" and \"McDonald's\"\n",
    "for line in file: # find strings that matched the criterion above, and then concatenate them together\n",
    "    line = pattern.findall(line)\n",
    "    line = \" \".join(str(i) for i in line) \n",
    "    lines_mod.append(line) # save modified lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mthe odified corpus\n",
    "file_mod = open(\"train_en_depunc.txt\",\"w\")\n",
    "for lines in lines_mod:\n",
    "    file_mod.write(lines + \"\\n\")\n",
    "file_mod.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus_file=\"train_en_depunc.txt\",window = 3, size=50) # train a model on the corpus without punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_window3size50\")\n",
    "# uncomment this line if you want to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"model_depunc\")\n",
    "# see the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and create output dataframes\n",
    "data_naming = pd.read_csv(\"data_naming.csv\")\n",
    "data_ld = pd.read_csv(\"data_lexdec.csv\")\n",
    "naming_simu = pd.DataFrame(columns=[\"isi\",\"prime\",\"target\",\"condition\",\"meanRT\",\"cosine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse through the model to get all cosine similarities\n",
    "for i in range(0,len(data_naming)):\n",
    "    prime = data_naming.loc[i,\"prime\"]\n",
    "    target = data_naming.loc[i,\"target\"]\n",
    "    isi = data_naming.loc[i,\"isi\"]\n",
    "    condition = data_naming.loc[i,\"condition\"]\n",
    "    meanRT = data_naming.loc[i,\"meanRT\"]\n",
    "    if (prime in vocab) and (target in vocab):\n",
    "        naming_simu.loc[i] = [isi,prime,target,condition,meanRT,model.wv.similarity(prime,target)]\n",
    "    else:\n",
    "        naming_simu.loc[i] = [isi,prime,target,condition,meanRT,np.NaN] # mark as NaN if the prime/target is not in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values\n",
    "nanip = naming_simu[naming_simu.isnull().values==True]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
